{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLEX TME 13 - Data Integration with Deep Learning\n",
    "\n",
    "The goal of the TME is to learn some techniques of data integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "- Molecular classification of leukemia data set of Golub et al. 1999 contains gene expressions of 72 patients and 3562 genes.\n",
    "- Breast cancer data set\n",
    "- Micr-Obes data (provided during the TME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "You will need to load at least the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "We will use `sklearn` and `keras` which is already installed on the machines. Repeat the same analyses for the data sets and make conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mises en forme des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Mise en forme des données Golub\n",
    "Xtrain=np.loadtxt(\"Golub_X\")\n",
    "print(Xtrain)\n",
    "\n",
    "Ytrain=np.loadtxt(\"Golub_y\")\n",
    "print(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mise en forme des données Breast Cancer \n",
    "#UID DE LA CLASSE ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mise en forme des données MicrObs\n",
    "Xtrain_microbENV=np.loadtxt(\"SPLEX_env.txt\")\n",
    "print(Xtrain_microbENV)\n",
    "Xtrain_microbHOST=np.loadtxt(\"SPLEX_host.txt\")\n",
    "print(Xtrain_microbHOST)\n",
    "Xtrain_micro=np.loadtxt(\"SPLEX_micro.txt\")\n",
    "print(Xtrain_micro)\n",
    "XtrainINTGERATION=np.concatenate(Xtrain_micro, Xtrain_microbENV, Xtrain_microbHOST, axis=1)\n",
    "print(XtrainINTGERATION)\n",
    "Ytrain_microb=np.loadtxt(\"classes.rtf\")\n",
    "print(Ytrain)\n",
    "\n",
    "#split the data in test data\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(XtrainINTGERATION))\n",
    " indices = np.random.permutation(len(iris_X))\n",
    ">>> iris_X_train = iris_X[indices[:-10]]\n",
    ">>> iris_y_train = iris_y[indices[:-10]]\n",
    ">>> iris_X_test  = iris_X[indices[-10:]]\n",
    ">>> iris_y_test  = iris_y[indices[-10:]]\n",
    "XtrainINTGERATION=[indices[-10:]]\n",
    "Xtrain_micro_test=XtrainINTGERATION\n",
    "print(Xtrain_micro_test)\n",
    "Ytrain_microb=np.loadtxt(\"classes.rtf\")\n",
    "print(Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using `sklearn`\n",
    "\n",
    "- Use a multi-layer perceptron <http://scikit-learn.org/stable/modules/neural_networks_supervised.html> to **define a model** (this is an example, you can choose different parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(solver='lbfgs', alpha=1e-7,hidden_layer_sizes=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to **learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to **predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTest_predicted = model.predict(XTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and find its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using `keras`\n",
    "\n",
    "Here is a tutorial on the `keras` <https://keras.io/getting-started/sequential-model-guide/>\n",
    "\n",
    "- Look in particular how to learn MLP for binary classification\n",
    "- Below it is an example! You can freely use a different number of layers and another optimizer!\n",
    "\n",
    "To **define a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=29))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to **learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(XTrain, yTrain,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "score = model.evaluate(XTest, yTest,\n",
    "                       batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to **predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(XTest, yTest,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform 10 fold-cross validation to compare the MLP classifiers of keras and sklearn on the Breast Cancer and Leukemia data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. In the Micr-Obes cohort, we aim to predict from three heterogeneous data sets (environment, host, and gut microbiota) whether a patient is a High Gene count person (i.e. healthy) or a Low Gene count individual (i.e. less healthy). Do not consider patients whose class in not known.\n",
    "\n",
    "- Run prediction on each separate data source (environment, host, and gut microbiota) and save accuracies\n",
    "- Do prediction from all provided data (concatenate environment, host, and gut micro- biota) to predict HGC/LGC.\n",
    "- What model is optimal in terms of accuracy?\n",
    "\n",
    "P.S. Be careful when you use deep learning methods. While trying to learn the image which is on the top, you can get the image that is on the bottom.\n",
    "\n",
    "![](000.jpg)![](001.jpg)\n",
    "\n",
    "<https://en.wikipedia.org/wiki/DeepDream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
